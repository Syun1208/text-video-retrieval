{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vit_jax import models\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "\n",
    "import googletrans\n",
    "import translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit\n",
    "\n",
    "mode = \"clip\"\n",
    "root_path = \"/home/toonies/AI-Challenge/AI_Challenge\"\n",
    "\n",
    "# Đường dẫn file text (đã tồn tại)\n",
    "ocr_inf = root_path + \"data/OCR_ASR/info_ocr_loc.txt\"\n",
    "\n",
    "\n",
    "# Đường dẫn để lưu file npy (chưa tồn tại)\n",
    "ocr_save_np = f\"data/models/npy_{mode}_ocr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translation:\n",
    "    def __init__(self, from_lang='vi', to_lang='en', mode='googletrans'):\n",
    "        # The class Translation is a wrapper for the two translation libraries, googletrans and translate. \n",
    "        self.__mode = mode\n",
    "        self.__from_lang = from_lang\n",
    "        self.__to_lang = to_lang\n",
    "\n",
    "        if mode in 'googletrans':\n",
    "            self.translator = googletrans.Translator()\n",
    "        elif mode in 'translate':\n",
    "            self.translator = translate.Translator(from_lang=from_lang,to_lang=to_lang)\n",
    "\n",
    "    def preprocessing(self, text):\n",
    "        \"\"\"\n",
    "        It takes a string as input, and returns a string with all the letters in lowercase\n",
    "        :param text: The text to be processed\n",
    "        :return: The text is being returned in lowercase.\n",
    "        \"\"\"\n",
    "        return text.lower()\n",
    "\n",
    "    def __call__(self, text):\n",
    "        \"\"\"\n",
    "        The function takes in a text and preprocesses it before translation\n",
    "        :param text: The text to be translated\n",
    "        :return: The translated text.\n",
    "        \"\"\"\n",
    "        text = self.preprocessing(text)\n",
    "        return self.translator.translate(text) if self.__mode in 'translate' \\\n",
    "                else self.translator.translate(text, dest=self.__to_lang).text\n",
    "    \n",
    "translate = Translation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check có hàng trống không và xóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114\n",
      "1114\n"
     ]
    }
   ],
   "source": [
    "###################### Nếu có thì sửa lại code (code hiện k xuất dc nội dung ocr) ###################### \n",
    "\n",
    "ocr_inf = root_path+\"/data/dicts/info_ocr.txt\"\n",
    "df_ocr = pd.read_csv(ocr_inf, delimiter=\",\", header=None)\n",
    "print(len(df_ocr))\n",
    "for i in range(len(df_ocr[2])):\n",
    "    if df_ocr[2][i]== \" \" or df_ocr[2][i]== \"\":\n",
    "        print(\"Index\",i)\n",
    "        df_ocr = df_ocr.drop(index=i)\n",
    "print(len(df_ocr))\n",
    "\n",
    "# output_file = root_path+\"/data/dicts/cleaned_info_ocr.txt\"\n",
    "# with open(output_file, 'w') as f:\n",
    "#      f.write(df_ocr.to_string(index=False))\n",
    "# print(\"Saved: \", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if mode == \"lit\":\n",
    "    model_name = 'LiT-B16B'\n",
    "    lit_model = models.get_model(model_name)\n",
    "    lit_variables = lit_model.load_variables()\n",
    "    tokenizer = lit_model.get_tokenizer()\n",
    "    image_preprocessing = lit_model.get_image_preprocessing()\n",
    "    pp = lit_model.get_pp()\n",
    "    translate = Translation()\n",
    "    os.system('TF_CPP_MIN_LOG_LEVEL=0')\n",
    "elif mode == \"clip\":\n",
    "    device = \"cuda\"\n",
    "    print(device)\n",
    "    model, preprocess = clip.load(\"ViT-B/16\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len of str is  23\n",
      "max len of str is  23\n",
      "max len of str is  40\n",
      "max len of str is  40\n",
      "max len of str is  113\n",
      "max len of str is  113\n",
      "max len of str is  113\n",
      "max len of str is  199\n",
      "max len of str is  199\n",
      "max len of str is  199\n",
      "max len of str is  199\n",
      "max len of str is  199\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  268\n",
      "max len of str is  270\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input 179 HT HD 06:32:05 Genisody Nick HVZZ MO1 Dingle Recreeningly Coang Angnisms HIV HIV LBN Mot Adixal Jounge Thiot Chivs Wt Test HIV Self HIV Monthly Y Mylan HIV HIV HIV Nighiem he is Deputy Governor General Satra Growing Soly Passionate Oil Hà Ngoc Son.At risk The Khangi is too long for context length 77",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     max_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(text)\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmax len of str is \u001b[39m\u001b[39m\"\u001b[39m,max_len)\n\u001b[0;32m---> 32\u001b[0m text \u001b[39m=\u001b[39m clip\u001b[39m.\u001b[39;49mtokenize([text])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     34\u001b[0m     text_features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode_text(text)\n",
      "File \u001b[0;32m~/anaconda3/envs/Tensor/lib/python3.9/site-packages/clip/clip.py:242\u001b[0m, in \u001b[0;36mtokenize\u001b[0;34m(texts, context_length, truncate)\u001b[0m\n\u001b[1;32m    240\u001b[0m             tokens[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m eot_token\n\u001b[1;32m    241\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00mtexts[i]\u001b[39m}\u001b[39;00m\u001b[39m is too long for context length \u001b[39m\u001b[39m{\u001b[39;00mcontext_length\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    243\u001b[0m     result[i, :\u001b[39mlen\u001b[39m(tokens)] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(tokens)\n\u001b[1;32m    245\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input 179 HT HD 06:32:05 Genisody Nick HVZZ MO1 Dingle Recreeningly Coang Angnisms HIV HIV LBN Mot Adixal Jounge Thiot Chivs Wt Test HIV Self HIV Monthly Y Mylan HIV HIV HIV Nighiem he is Deputy Governor General Satra Growing Soly Passionate Oil Hà Ngoc Son.At risk The Khangi is too long for context length 77"
     ]
    }
   ],
   "source": [
    "df_ocr = pd.read_csv(ocr_inf, delimiter=\",\", header=None)\n",
    "root_dicts = root_path+\"data/dicts/\"\n",
    "index = 0\n",
    "if mode == \"lit\":\n",
    "    for path in df_ocr[0].unique():\n",
    "        os.makedirs(f\"{root_dicts}/{path}\", exist_ok = True)\n",
    "        re_feats = []\n",
    "        for i in range(len(df_ocr.loc[df_ocr[0] == path])):\n",
    "            text = translate(df_ocr[2][index]) # anhasd asada s\n",
    "            text = [translate(text),]\n",
    "            print(f\"Idx: {index},{path}, {i}\")\n",
    "            tokens = tokenizer([text])\n",
    "            _, text_embeddings, _ = lit_model.apply(lit_variables, tokens=tokens)\n",
    "\n",
    "            index += 1\n",
    "            re_feats.append(text_embeddings)\n",
    "        outfile = f'{ocr_save_np}/{path}.npy'\n",
    "        np.save(outfile, re_feats)\n",
    "        print(f\"Save {outfile}\")\n",
    "    print(\"num of index \", index)\n",
    "\n",
    "elif mode == \"clip\":\n",
    "    max_len = 0\n",
    "    for path in df_ocr[0].unique():\n",
    "        os.makedirs(f\"{root_dicts}/{path}\", exist_ok = True)\n",
    "        re_feats = []\n",
    "        for i in range(len(df_ocr.loc[df_ocr[0] == path])):\n",
    "            text = translate(df_ocr[2][index])\n",
    "            if len(text) >= max_len:\n",
    "                max_len = len(text)\n",
    "            print(\"max len of str is \",max_len)\n",
    "            text = clip.tokenize([text]).to(device)\n",
    "            with torch.no_grad():\n",
    "                text_features = model.encode_text(text)\n",
    "            text_features = text_features.cpu().detach().numpy().astype(np.float32)\n",
    "            index += 1\n",
    "            re_feats.append(text_features)\n",
    "        outfile = f'{ocr_save_np}/{path}.npy'\n",
    "        np.save(outfile, re_feats)\n",
    "        print(f\"Save {outfile}\")\n",
    "    print(\"num of index \", index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create bin file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "from langdetect import detect\n",
    "def process_name(name: int):\n",
    "    return \"0\"*(6-len(str(name))) + str(name)\n",
    "\n",
    "def write_bin_file_ocr(bin_path: str, root_path: str, method='cosine', feature_shape= 768): # Edit 512, 768\n",
    "  idx = 0\n",
    "  id = 0\n",
    "  if method in 'L2':\n",
    "    index = faiss.IndexFlatL2(feature_shape)\n",
    "  elif method in 'cosine':\n",
    "    index = faiss.IndexFlatIP(feature_shape)\n",
    "  else:\n",
    "    assert f\"{method} not supported\"\n",
    "  \n",
    "  for _ in range(len(df_ocr[1])):\n",
    "    \n",
    "    # Create image path \"*/*/*.jpg\"\n",
    "    image_path = f\"{root_path}/{df_ocr[0][idx]}/{process_name(df_ocr[1][idx])}.jpg\" \n",
    "\n",
    "    # Call *.npy path that was created\n",
    "    video_name = f'{df_ocr[0][idx]}.npy'\n",
    "    LIT_name = f\"data/models/npy_ocr\" # Edit \n",
    "    feat_path = os.path.join(LIT_name, video_name) \n",
    "\n",
    "    # Load npy file\n",
    "    feats = np.load(feat_path)\n",
    "    ids = os.listdir(re.sub('/\\d+.jpg','',image_path))\n",
    "    ids = sorted(ids, key=lambda x:int(x.split('.')[0]))\n",
    "\n",
    "########################################################################\n",
    " # Output ID 1, 2, 3, 4 . if len path == id reset id\n",
    "    feat = feats[id]\n",
    "    id = 0 if len(df_ocr.loc[df_ocr[0] == df_ocr[0][1048]]) == (id + 1) else id + 1\n",
    "\n",
    "    print(\"ID: \", id)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "    \n",
    "    # print(feat.shape)\n",
    "    feat = feat.astype(np.float32).reshape(1,-1)\n",
    "    # print(\"##########################################\")\n",
    "    # print(\" Feat after reshape: \", feat.shape)\n",
    "    index.add(feat)\n",
    "    \n",
    "    idx +=1\n",
    "\n",
    "  faiss.write_index(index, os.path.join(bin_path, f\"faiss_LIT_OCR_{method}.bin\"))\n",
    "\n",
    "  print(f'Saved {os.path.join(bin_path, f\"faiss_LIT_OCR_{method}.bin\")}')\n",
    "  print(f\"Number of Index: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_bin_file_ocr(bin_path = \"data/models\", root_path = \"data/KeyFramesC00_V00/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and search with bin file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.translate_processing import Translation\n",
    "\n",
    "class MyFaiss:\n",
    "  def __init__(self, bin_file: str, mode = \"lit\"):    \n",
    "    self.index = self.load_bin_file(bin_file)\n",
    "    self.translate = Translation()\n",
    "    ocr_inf = \"data/OCR_ASR/info_ocr_loc.txt\"\n",
    "    self.df_ocr = pd.read_csv(ocr_inf, delimiter=\",\", header=None)\n",
    "    if mode == \"lit\":\n",
    "      os.system('TF_CPP_MIN_LOG_LEVEL=0')\n",
    "      self.lit_model = models.get_model(\"LiT-B16B\")\n",
    "      self.lit_var = self.lit_model.load_variables()\n",
    "      self.tokenizer = self.lit_model.get_tokenizer()\n",
    "      \n",
    "  def load_bin_file(self, bin_file: str):\n",
    "    return faiss.read_index(bin_file)\n",
    "  \n",
    "  def text_search(self, text, k):\n",
    "    if detect(text) == 'vi':\n",
    "      text = self.translate(text)\n",
    "    text = self.translate(text)\n",
    "    print(\"Text translation: \", text)\n",
    "    tokens = self.tokenizer([text])\n",
    "    _, text_features, _ = self.lit_model.apply(self.lit_var, tokens=tokens)\n",
    "    scores, idx_image = self.index.search(np.array(text_features), k=k)\n",
    "    idx_image = idx_image.flatten()\n",
    "    print(\"idx_img \",idx_image)\n",
    "    return idx_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Reusing local copy: LiT-B16B.npz\n",
      "Text translation:  ho chi minh city young people with hand, foot and mouth disease increased more than a month\n",
      "idx_img  [224 220 218 221 223 222 404 542 253]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    faiss_search = MyFaiss(bin_file='data/models/faiss_LIT_OCR_cosine.bin')\n",
    "    text = \"tphcm trẻ mắc bệnh tay chân miệng tăng gấp lần trong một tháng\"\n",
    "    idx_image = faiss_search.text_search(text, k=9)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test  function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Reusing local copy: LiT-B16B.npz\n",
      "Text translation:  himship over billion dong to embellish the landscape of the monument\n",
      "Time inference of lit and ocr: 0.9316995143890381\n",
      "[11192, 11209, 19158, 10995, 19119, 11246, 14650, 14591, 19257]\n"
     ]
    }
   ],
   "source": [
    "from vit_jax import models\n",
    "from utils.translate_processing import Translation\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from langdetect import detect\n",
    "import time\n",
    "\n",
    "def time_complexity(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        results = func(*args, **kwargs)\n",
    "        print('Time inference of {} and ocr: {}'.format(args[0].mode, time.time() - start))\n",
    "        return results\n",
    "    return wrapper\n",
    "\n",
    "class Faiss_OCR():\n",
    "    def __init__(self, bin_file: str, info_file: str , root_img:str, mode = \"lit\"):\n",
    "        self.df_ocr = pd.read_csv(info_file, delimiter=\",\", header=None)\n",
    "        self.translate = Translation()\n",
    "        self.index = self.load_bin_file(bin_file)\n",
    "        self.root_img = root_img\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == \"lit\":\n",
    "            os.system('TF_CPP_MIN_LOG_LEVEL=0')\n",
    "            self.lit_model = models.get_model(\"LiT-B16B\")\n",
    "            self.lit_var = self.lit_model.load_variables()\n",
    "            self.tokenizer = self.lit_model.get_tokenizer()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def process_name_img(self, name: int):\n",
    "        return \"0\"*(6-len(str(name))) + str(name)\n",
    "\n",
    "    def convert_idx_to_path(self,idx_image):\n",
    "        path_arr = []\n",
    "        for idx in idx_image:\n",
    "            path = f\"{self.root_img}/{self.df_ocr[0][idx]}/{self.process_name_img(self.df_ocr[1][idx])}.jpg\"\n",
    "            path_arr.append(path)\n",
    "        return path_arr\n",
    "\n",
    "    def load_bin_file(self, bin_file):\n",
    "        return faiss.read_index(bin_file)\n",
    "    \n",
    "    @time_complexity\n",
    "    def text_search(self, text, k = 9):\n",
    "        if detect(text) == 'vi':\n",
    "            text = self.translate(text)\n",
    "        text = self.translate(text)\n",
    "        print(\"Text translation: \", text)\n",
    "        tokens = self.tokenizer([text])\n",
    "        _, text_features, _ = self.lit_model.apply(self.lit_var, tokens=tokens)\n",
    "        scores, idx_image = self.index.search(np.array(text_features), k=k)\n",
    "        idx_image = idx_image.flatten()\n",
    "        # arr_path = self.convert_idx_to_path(idx_image)\n",
    "        arr_paths = [self.df_ocr[1][id_image] for id_image in idx_image]\n",
    "        return arr_paths\n",
    "    \n",
    "def main():\n",
    "    faiss_search = Faiss_OCR(bin_file='data/models/faiss_LIT_OCR_cosine.bin', info_file = \"data/OCR_ASR/info_ocr_loc.txt\", root_img = \"data/KeyFramesC00_V00\")\n",
    "    text = \"himship trên tỷ đồng tôn tạo cảnh quan di tích\"\n",
    "    idx_image = faiss_search.text_search(text, k=9)\n",
    "    print(idx_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name_img( name: int):\n",
    "    return \"0\"*(6-len(str(name))) + str(name)\n",
    "\n",
    "def convert_idx_to_path(idx_image):\n",
    "    return f\"KeyFramesC00_V00/{df_ocr[0][idx_image]}/{process_name_img(df_ocr[1][idx_image])}.jpg\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ocr = pd.read_csv(\"data/OCR_ASR/info_ocr_loc.txt\", delimiter=\",\", header=None)\n",
    "file_path = \"data/OCR_ASR/update_info_ocr.txt\"\n",
    "items = []\n",
    "for i in range(len(df_ocr)):\n",
    "    item = convert_idx_to_path(i)\n",
    "    items.append(item)\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    for i in items:\n",
    "        file.write(\"%s\\n\" %i)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update OCR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 15:12:46.085322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Reusing local copy: LiT-B16B.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 15:12:49.589474: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-22 15:12:49.656316: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text translation:  himship over billion dong to embellish the landscape of the monument\n",
      "Time inference of lit and ocr: 3.221402645111084\n",
      "[[0.8692388  0.8692388  0.85251015 0.850931   0.8483517  0.8375005\n",
      "  0.8212406  0.8178458  0.8167915 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from vit_jax import models\n",
    "from utils.translate_processing import Translation\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from langdetect import detect\n",
    "import time\n",
    "\n",
    "def time_complexity(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        results = func(*args, **kwargs)\n",
    "        print('Time inference of {} and ocr: {}'.format(args[0].mode, time.time() - start))\n",
    "        return results\n",
    "    return wrapper\n",
    "\n",
    "class Faiss_OCR():\n",
    "    def __init__(self, bin_file: str, info_file: str , root_img:str, mode = \"lit\"):\n",
    "        self.df_ocr = pd.read_csv(info_file, delimiter=\",\", header=None)\n",
    "        self.translate = Translation()\n",
    "        self.index = self.load_bin_file(bin_file)\n",
    "        self.root_img = root_img\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == \"lit\":\n",
    "            os.system('TF_CPP_MIN_LOG_LEVEL=0')\n",
    "            self.lit_model = models.get_model(\"LiT-B16B\")\n",
    "            self.lit_var = self.lit_model.load_variables()\n",
    "            self.tokenizer = self.lit_model.get_tokenizer()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "    def load_bin_file(self, bin_file):\n",
    "        return faiss.read_index(bin_file)\n",
    "    \n",
    "    @time_complexity\n",
    "    def text_search(self, text, k = 9):\n",
    "        if detect(text) == 'vi':\n",
    "            text = self.translate(text)\n",
    "        text = self.translate(text)\n",
    "        print(\"Text translation: \", text)\n",
    "        tokens = self.tokenizer([text])\n",
    "        _, text_features, _ = self.lit_model.apply(self.lit_var, tokens=tokens)\n",
    "        scores, idx_image = self.index.search(np.array(text_features), k=k)\n",
    "        idx_image = idx_image.flatten()\n",
    "        return [self.root_img+self.df_ocr[0][id_image] for id_image in idx_image], scores\n",
    "    \n",
    "def main():\n",
    "    faiss_search = Faiss_OCR(bin_file='data/models/faiss_LIT_OCR_cosine.bin', info_file = \"data/OCR_ASR/update_info_ocr.txt\", root_img = \"data/\")\n",
    "    text = \"himship trên tỷ đồng tôn tạo cảnh quan di tích\"\n",
    "    idx_image, scores = faiss_search.text_search(text, k=9)\n",
    "    print(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
